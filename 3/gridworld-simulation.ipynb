{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # GridWorld Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, x, y):\n",
    "        self.state = (x, y)\n",
    "        self.pi = [.25, .25, .25, .25]\n",
    "        self.actions = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n",
    "                   \n",
    "        # counters\n",
    "        self.accum_rewards = defaultdict(int)\n",
    "        self.cell_freqs = defaultdict(int)\n",
    "    \n",
    "    def choose_action(self):\n",
    "        i = np.random.choice(range(len(self.actions)), p=self.pi)\n",
    "        return self.actions[i], self.pi[i]\n",
    "    \n",
    "    def update_credit(self, s_temp, stplus1, r):\n",
    "        # if it didin't move is because it jumped out of the grid\n",
    "        if stplus1 == self.state:\n",
    "            credit_cell = self.state\n",
    "        else:\n",
    "            credit_cell = s_temp            \n",
    "            \n",
    "        self.cell_freqs[credit_cell] += 1\n",
    "        self.accum_rewards[credit_cell] += r \n",
    "        \n",
    "        return credit_cell\n",
    "    \n",
    "    def update_state(self, stplus1):   \n",
    "        self.state = stplus1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Gridworld:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        \n",
    "        # (i, j), 0,0) is the top-left corner of the grid\n",
    "        self.A = [(0, 1), (4, 1), 10]\n",
    "        self.B = [(0, 3), (2, 3), 5]\n",
    "    \n",
    "    def compute_reward(self, s_temp):\n",
    "        r = 0\n",
    "        \n",
    "        if s_temp == self.A[0]:\n",
    "            r = self.A[2]         \n",
    "        elif s_temp == self.B[0]:\n",
    "            r = self.B[2]          \n",
    "        elif s_temp[0]<0 or s_temp[0]>self.n-1:\n",
    "            r = -1           \n",
    "        elif s_temp[1]<0 or s_temp[1]>self.n-1:\n",
    "            r = -1\n",
    "        \n",
    "        return r\n",
    "    \n",
    "    \n",
    "    def next_state(self, st, a):\n",
    "        \n",
    "        s_temp = (st[0] + a[0], st[1] + a[1])  # element-wise addition of tuples\n",
    "        stplus1 = s_temp\n",
    "        \n",
    "        if stplus1 == self.A[0]:\n",
    "            stplus1 = self.B[1]\n",
    "            \n",
    "        elif stplus1 == self.B[0]:\n",
    "            stplus1 = self.B[1]\n",
    "            \n",
    "        elif stplus1[0]<0 or stplus1[0]>self.n-1:\n",
    "            stplus1 = st\n",
    "            \n",
    "        elif stplus1[1]<0 or stplus1[1]>self.n-1:\n",
    "            stplus1 = st\n",
    "        \n",
    "        return s_temp, stplus1\n",
    "\n",
    "\n",
    "    def run(self, agent, num_steps):\n",
    "        \n",
    "        for _ in range(num_steps):\n",
    "            a, p = agent.choose_action()\n",
    "            s_temp, stplus1 = self.next_state(agent.state, a)   \n",
    "            r = self.compute_reward(s_temp)\n",
    "            agent.update_credit(s_temp, stplus1, r)\n",
    "            agent.update_state(stplus1)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 5\n",
    "steps = 10000\n",
    "\n",
    "grid_world = Gridworld(n)\n",
    "agent = Agent(2, 2)\n",
    "grid_world.run(agent, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -0.45  10.    -0.23   5.    -0.52]\n",
      " [ -0.24   0.     0.     0.    -0.25]\n",
      " [ -0.23   0.     0.     0.    -0.25]\n",
      " [ -0.28   0.     0.     0.    -0.23]\n",
      " [ -0.51  -0.25  -0.29  -0.23  -0.51]]\n"
     ]
    }
   ],
   "source": [
    "r = np.zeros(shape=(n, n))\n",
    "f = np.zeros(shape=(n, n))\n",
    "g = np.zeros(shape=(n, n))\n",
    "for s in agent.cell_freqs.keys():\n",
    "    r[s] = agent.accum_rewards[s] \n",
    "    f[s] = agent.cell_freqs[s]\n",
    "    g[s] = agent.accum_rewards[s] / float(max(1, agent.cell_freqs[s]))\n",
    "\n",
    "print np.round(g, decimals=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
